---
layout: concept
title: Set of Gestures
description: set of gestures in interactive visualizations
---
@work
### What's a gesture?
Gestures as the input through which users interact with the interface of an display. But where exactly does it start and where does it end? Is it just a movement or maybe more? 
Kurtenbach and Hulteen claim: "A gesture is a motion of the body that contains information. Waving goodbye is a gesture. Pressing a key on a keyboard is not a gesture because the motion of a finger on its way to hitting a key is neither observed nor significant. All that matters is which key was pressed". 
According to this a gesture can be defined as a movement of the body that is performed to convey meaning. Meaning therefore implicitly creates the boundaries of a single gesture, which consists of everything that must necessarily be performed to encode the meaning. Meaning can only be conveyed successfully in a communication space that uses languages all the participants are able to speak. 

### Gestures on elastic displays
 The communication space of elastic displays includes users performing movements with their hands and a display that observes the deformation of its surface, mostly from beyond. We define a set of gestures that describes the gestures performable on elastic display from the user's point of view. The user's intention to "tell" the display something meaningful creates the boundaries that define the start and end of a single gesture. In terms of user-centered design the technical expression of gestures has to be derived from this user-defined gesture set. More on technical gesture recognition can be found under [tracking technologies]({{ site.baseurl }}/concepts/tracking-technologies).

### Defining a set of gestures for elastic displays
Several attemps have been made to collect, categorize and describe the gestural input modalities on elastic displays. In [User-Defined Gestures for Elastic, Deformable Displays]({{ site.baseurl }}/resources/#references) Troiano et al. report a guessability study to describe the gesture set users prefer to perform on elastic, deformable displays. An investigation of tabletop gestures can be found in [Investigating Gestures on Elastic Tabletops]({{ site.baseurl }}/resources/#references) by Kammer et al. In [Gestures in Human-Computer-Interaction]({{ site.baseurl }}/resources/#references) Muser gives a general overwiew of different approaches for gesture classification that can be used to formalize the findings in other research papers towards a more complete and structured gesture classification. The video [Obake: interactions with a 2.5D elastic display]({{ site.baseurl }}/resources/#links) contains a collection of gestural interactions on elastic 2.5D displays.

TROIANO (gestures and preferences):
1. Push 18 
2. Drag 12 
3. Expand 9 
4. Grab 9 
5. Pinch 8 
6. Pull 6 
7. Hold 5 
8. Rotate 3 
9. Shrink 3 
10. Draw a shape 3 
11. Swipe 3  
12. Tap 3 
13. Twist 2 
14. Squeeze 2 
15. Slide 1 
16. Stretch 1 
17. Gather 1 
18. Release 1
19. Lasso 0,9 
20. Punch 0,7 
21. Tilt 0,6 
22. Follow the contour 0,4 
23. Slice 0,3 
24. Throw 0,3 
25. Draw a line 0,2 
26. Slingshot 0,2
27. Round a shape 0,1 
28. Rub 0,1 
29. Spread 0,1 

OBAKE:
1. Intrude (more)
2. Extrude (more)
3. S-bend
4. Stich
5. Compress
6. Pull (shapes)
7. Push (shapes)
8. Prod
9. Friction
10. Warp

## Own catalogue
...

